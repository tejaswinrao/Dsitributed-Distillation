{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='C:\\\\Users\\\\Tejaswi\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "dataset, info = tfds.load('mnist', as_supervised = True, with_info = True)\n",
    "dataset_test, dataset_train = dataset['test'], dataset['train']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\n",
    "dataset_test = dataset_test.map(convert_types).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Model):\n",
    "    def __init__(self, channel_in = 64, channel_out = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        channel = channel_out // 4\n",
    "        \n",
    "        self.conv1 = Conv2D(channel, kernel_size = (1, 1), padding = \"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.av1 = Activation(tf.nn.relu)\n",
    "        self.conv2 = Conv2D(channel, kernel_size = (3, 3), padding = \"same\")\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.av2 = Activation(tf.nn.relu)\n",
    "        self.conv3 = Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.shortcut = self._shortcut(channel_in, channel_out)\n",
    "        self.add = Add()\n",
    "        self.av3 = Activation(tf.nn.relu)\n",
    "        \n",
    "    def call(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.bn1(h)\n",
    "        h = self.av1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.av2(h)\n",
    "        h = self.conv3(h)\n",
    "        h = self.bn3(h)\n",
    "        shortcut = self.shortcut(x)\n",
    "        h = self.add([h, shortcut])\n",
    "        y = self.av3(h)\n",
    "        return y\n",
    "    \n",
    "    def _shortcut(self, channel_in, channel_out):\n",
    "        if channel_in == channel_out:\n",
    "            return lambda x : x\n",
    "        else:\n",
    "            return self._projection(channel_out)\n",
    "        \n",
    "    def _projection(self, channel_out):\n",
    "        return Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
    "           \n",
    "class ResNet50(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            # conv2_x\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 256),\n",
    "            [\n",
    "                ResidualBlock(256, 256) for _ in range(2)                \n",
    "            ],\n",
    "            # conv3_x\n",
    "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(512, 512) for _ in range(4)                \n",
    "            ],\n",
    "            # conv4_x\n",
    "            Conv2D(1024, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(1024, 1024) for _ in range(6)                \n",
    "            ],\n",
    "            # conv5_x\n",
    "            Conv2D(2048, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(2048, 2048) for _ in range(3)\n",
    "            ],\n",
    "            # last part\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self._layers:\n",
    "            if isinstance(layer, list):\n",
    "                for l in layer:\n",
    "                    x = l(x)    \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "       \n",
    "    \n",
    "model = ResNet50((28, 28, 1), 10)\n",
    "model.build(input_shape = (None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "When subclassing the `Model` class, you should implement a `call` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-64a3ad285b39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;31m#model = ResNet4((28, 28, 1),10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m#model = ResNet8((28,28,1),10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    441\u001b[0m                            'method accepts an `inputs` argument.')\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m           raise ValueError('You cannot build your model by calling `build` '\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m--> 476\u001b[1;33m     raise NotImplementedError('When subclassing the `Model` class, you should '\n\u001b[0m\u001b[0;32m    477\u001b[0m                               'implement a `call` method.')\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: When subclassing the `Model` class, you should implement a `call` method."
     ]
    }
   ],
   "source": [
    "class ResNet2(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "\n",
    "class ResNet8(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 256),\n",
    "            [\n",
    "                ResidualBlock(256, 256) for _ in range(2)                \n",
    "            ],\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "        \n",
    "class ResNet16(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 256),\n",
    "            [\n",
    "                ResidualBlock(256, 256) for _ in range(2)                \n",
    "            ],\n",
    "            # conv3_x\n",
    "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(512, 512) for _ in range(4)                \n",
    "            ],\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "            \n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self._layers:\n",
    "            if isinstance(layer, list):\n",
    "                for l in layer:\n",
    "                    x = l(x)    \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet2(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "\n",
    "class ResNet8(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 256),\n",
    "            [\n",
    "                ResidualBlock(256, 256) for _ in range(2)                \n",
    "            ],\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "        \n",
    "class ResNet16(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 256),\n",
    "            [\n",
    "                ResidualBlock(256, 256) for _ in range(2)                \n",
    "            ],\n",
    "            # conv3_x\n",
    "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(512, 512) for _ in range(4)                \n",
    "            ],\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "            \n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self._layers:\n",
    "            if isinstance(layer, list):\n",
    "                for l in layer:\n",
    "                    x = l(x)    \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1, momentum = 0.9, decay =  0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "        \n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3002485036849976, Accuracy: 51.650001525878906, Test Loss: 0.2636105716228485, Test Accuracy: 91.98999786376953, spent_time: 803.9731658498446 min\n",
      "Epoch 2, Loss: 0.7623071670532227, Accuracy: 72.47916412353516, Test Loss: 0.21235550940036774, Test Accuracy: 93.63500213623047, spent_time: 838.6656322002411 min\n",
      "Epoch 3, Loss: 0.5549966096878052, Accuracy: 80.27555084228516, Test Loss: 0.16892266273498535, Test Accuracy: 94.91999816894531, spent_time: 872.2124958237013 min\n",
      "Epoch 4, Loss: 0.4454777240753174, Accuracy: 84.33708190917969, Test Loss: 0.1422969251871109, Test Accuracy: 95.75749969482422, spent_time: 904.5418907602628 min\n",
      "Epoch 5, Loss: 0.3765123784542084, Accuracy: 86.87133026123047, Test Loss: 0.13357047736644745, Test Accuracy: 96.0479965209961, spent_time: 937.7575536171595 min\n",
      "Epoch 6, Loss: 0.32903075218200684, Accuracy: 88.61054992675781, Test Loss: 0.12025441229343414, Test Accuracy: 96.4366683959961, spent_time: 973.618462963899 min\n",
      "Epoch 7, Loss: 0.29459282755851746, Accuracy: 89.87452697753906, Test Loss: 0.11379466205835342, Test Accuracy: 96.61714172363281, spent_time: 1010.3070427060127 min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d279ba73e539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_label\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 400\n",
    "start_time = time.time()\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epoch):    \n",
    "    for image, label in dataset_train:\n",
    "        for _image, _label in datagen.flow(image, label, batch_size = batch_size):\n",
    "            train_step(_image, _label)\n",
    "            break\n",
    "        \n",
    "    for test_image, test_label in dataset_test:\n",
    "        test_step(test_image, test_label)\n",
    "        \n",
    "    train_accuracies.append(train_accuracy.result())\n",
    "    test_accuracies.append(test_accuracy.result())    \n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, spent_time: {} min'\n",
    "    spent_time = time.time() - start_time\n",
    "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100, spent_time / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracies, label = 'Train Accuracy')\n",
    "plt.plot(test_accuracies, linestyle = 'dashed', label = 'Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
